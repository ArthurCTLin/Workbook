{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SimCLR Eval.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMs3gDSe/QjQ1cZI4gStDBv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArthurCTLin/Workbook/blob/main/SimCLR/SimCLR_Eval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries\n"
      ],
      "metadata": {
        "id": "VykQP-iAYc4p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HsoOo3qOhcZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import sys\n",
        "import numpy as np\n",
        "import os\n",
        "import yaml\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import torchvision\n",
        "\n",
        "# \"ConcatDataset\" and \"Subset\" are possibly useful when doing semi-supervised learning.\n",
        "from torch.utils.data import ConcatDataset, DataLoader, Subset, Dataset\n",
        "from torchvision.datasets import DatasetFolder, STL10\n",
        "from torchvision import datasets, transforms, models\n",
        "\n",
        "# This is for the progress bar.\n",
        "from tqdm import tqdm\n",
        "\n",
        "# set a random seed for reproducibility\n",
        "myseed = 42069  \n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(myseed)\n",
        "torch.manual_seed(myseed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(myseed)\n",
        "    \n",
        "    \n",
        "NUM_WORKERS = os.cpu_count()\n",
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"Device: \", device)\n",
        "print(\"Number of workers: \", NUM_WORKERS)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model\n",
        "* SimCLR: pretrained model\n",
        "  * Encoder: ResNet-50\n",
        "  * "
      ],
      "metadata": {
        "id": "OWdrWVSoZUWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimCLR(nn.Module):\n",
        "\n",
        "    def __init__(self, encoder):\n",
        "        super(SimCLR, self).__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "\n",
        "        dim_mlp = self.encoder.fc.in_features\n",
        "        self.encoder.fc = nn.Sequential(nn.Linear(dim_mlp, dim_mlp),\n",
        "                          nn.ReLU(),\n",
        "                          self.encoder.fc\n",
        "                          )\n",
        "                    \n",
        "    def forward(self, x):\n",
        "        return self.encoder(x)"
      ],
      "metadata": {
        "id": "WWo6o7WVU03_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DownstreamModel(nn.Module):\n",
        "    def __init__(self, premodel, num_classes):\n",
        "        super(DownstreamModel, self).__init__()\n",
        "        \n",
        "        self.premodel = premodel\n",
        "        self.num_classes = num_classes\n",
        "        self.lastlayer = nn.Linear(128, self.num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.premodel(x)\n",
        "        x = self.lastlayer(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "7IKQfxwOU2JH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"../input/stl10-50epoch/model.ckpt\"\n",
        "\n",
        "projection_dim = 128\n",
        "encoder = models.resnet50(pretrained=False, num_classes=projection_dim)\n",
        "\n",
        "premodel = SimCLR(encoder)\n",
        "premodel.load_state_dict(torch.load(model_path))\n",
        "\n",
        "ds_model = DownstreamModel(premodel, 10).to(device)"
      ],
      "metadata": {
        "id": "yYO-cqZwU9xs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Downstream Dataset\n",
        "* Splitted STL10 training dataset with the ratio of 8:2 as training, validation dataset\n",
        "* Since I want to check the performance of the SimCLR pretrained model, the data augmentation is not adopted."
      ],
      "metadata": {
        "id": "rMPd-2Q0ZxJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "])"
      ],
      "metadata": {
        "id": "YVSwCVS_VEG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 256\n",
        "\n",
        "dataset = STL10(root='STL10', split ='train', download=True, transform=transform)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "valid_size = len(dataset) - train_size\n",
        "train_set, valid_set = torch.utils.data.random_split(dataset, [train_size, valid_size])\n",
        "\n",
        "test_set = STL10(root='STL10', split ='test', download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=NUM_WORKERS)\n",
        "valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=NUM_WORKERS)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=NUM_WORKERS)"
      ],
      "metadata": {
        "id": "w3hY5_-iVG7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimizer & criterion"
      ],
      "metadata": {
        "id": "2pUnyelEahbA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SimCLR_DS_save_path = \"SimCLR_DS_model.ckpt\"\n",
        "n_epochs = 100\n",
        "\n",
        "optimizer = torch.optim.Adam(ds_model.parameters(), lr=5e-4, weight_decay=1e-4)\n",
        "criterion = torch.nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "4ennkoLsVJMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "7mCVeX02aq_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_acc = 0.0\n",
        "valid_acc = 0.0\n",
        "valid_loss = 0.0\n",
        "\n",
        "train_loss_record = []\n",
        "valid_loss_record = []\n",
        "train_acc_record = []\n",
        "valid_acc_record = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    ds_model.train()\n",
        "\n",
        "    # These are used to record information in training.\n",
        "    train_loss = []\n",
        "    train_accs = []\n",
        "\n",
        "    # Iterate the training set by batches.\n",
        "    for batch in tqdm(train_loader):\n",
        "\n",
        "        imgs, labels = batch\n",
        "\n",
        "        logits = ds_model(imgs.to(device))\n",
        "        loss = criterion(logits, labels.to(device))\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n",
        "\n",
        "        train_loss.append(loss.item())\n",
        "        train_accs.append(acc)\n",
        "\n",
        "    # The average loss and accuracy of the training set is the average of the recorded values.\n",
        "    train_loss = sum(train_loss) / len(train_loss)\n",
        "    train_acc = sum(train_accs) / len(train_accs)\n",
        "\n",
        "    # Print the information.\n",
        "    print(f\"[ Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}\")\n",
        "\n",
        "    # ---------- Validation ----------\n",
        "    ds_model.eval()\n",
        "\n",
        "    # These are used to record information in validation.\n",
        "    valid_loss = []\n",
        "    valid_accs = []\n",
        "\n",
        "    # Iterate the validation set by batches.\n",
        "    for batch in tqdm(valid_loader):\n",
        "        \n",
        "        imgs, labels = batch\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = ds_model(imgs.to(device))\n",
        "\n",
        "        loss = criterion(logits, labels.to(device))\n",
        "\n",
        "        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n",
        "\n",
        "        # Record the loss and accuracy.\n",
        "        valid_loss.append(loss.item())\n",
        "        valid_accs.append(acc)\n",
        "\n",
        "    # The average loss and accuracy for entire validation set is the average of the recorded values.\n",
        "    valid_loss = sum(valid_loss) / len(valid_loss)\n",
        "    valid_acc = sum(valid_accs) / len(valid_accs)\n",
        "\n",
        "    # Print the information.\n",
        "    print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n",
        "    \n",
        "    # ------Record every time information------\n",
        "    if valid_acc > best_acc:\n",
        "        best_acc = valid_acc\n",
        "        torch.save(ds_model.state_dict(), SimCLR_DS_save_path)\n",
        "    train_loss_record.append(train_loss)\n",
        "    valid_loss_record.append(valid_loss)\n",
        "    train_acc_record.append(train_acc)\n",
        "    valid_acc_record.append(valid_acc)"
      ],
      "metadata": {
        "id": "YGAubKWMVJq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "4zmB78gjayiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds_model.load_state_dict(torch.load(SimCLR_DS_save_path))\n",
        "\n",
        "ds_model.eval()\n",
        "\n",
        "test_loss = []\n",
        "test_accs = []\n",
        "test_acc = []\n",
        "\n",
        "for batch in tqdm(test_loader):\n",
        "    imgs, labels = batch\n",
        "  \n",
        "    with torch.no_grad():\n",
        "        logits = ds_model(imgs.to(device))\n",
        "  \n",
        "    loss = criterion(logits, labels.to(device))\n",
        "    acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n",
        "\n",
        "    test_loss.append(loss)\n",
        "    test_accs.append(acc)\n",
        "\n",
        "test_loss = sum(test_loss)/len(test_loss)\n",
        "test_acc = sum(test_accs)/len(test_accs)\n",
        "print(f\"loss = {test_loss:.5f}, acc = {test_acc:.5f}\")"
      ],
      "metadata": {
        "id": "vjfjoGecVXDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Baseline of ResNet50\n",
        "The unpretained ResNet50 model is taken as the baseline to check the performance of SimCLR model."
      ],
      "metadata": {
        "id": "jYr6a1ora1dw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNet50 Model\n",
        "model_resnet50 = models.resnet50(pretrained=False)\n",
        "for param in model_resnet50.parameters():\n",
        "    param.requires_grad = True\n",
        "model_resnet50.fc = torch.nn.Linear(model_resnet50.fc.in_features, 10)\n",
        "model_resnet50 = model_resnet50.to(device)"
      ],
      "metadata": {
        "id": "Kps72lY7VYQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ResNet50_save_path = \"ResNet50_model.ckpt\"\n",
        "optimizer = torch.optim.Adam(model_resnet50.parameters(), lr=5e-4, weight_decay=1e-4)\n",
        "criterion = torch.nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "nXYAT3pPVaEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_acc = 0.0\n",
        "valid_acc = 0.0\n",
        "valid_loss = 0.0\n",
        "\n",
        "train_loss_record = []\n",
        "valid_loss_record = []\n",
        "train_acc_record = []\n",
        "valid_acc_record = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    model_resnet50.train()\n",
        "\n",
        "    # These are used to record information in training.\n",
        "    train_loss = []\n",
        "    train_accs = []\n",
        "\n",
        "    # Iterate the training set by batches.\n",
        "    for batch in tqdm(train_loader):\n",
        "\n",
        "        imgs, labels = batch\n",
        "\n",
        "        logits = model_resnet50(imgs.to(device))\n",
        "        loss = criterion(logits, labels.to(device))\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n",
        "\n",
        "        train_loss.append(loss.item())\n",
        "        train_accs.append(acc)\n",
        "\n",
        "    # The average loss and accuracy of the training set is the average of the recorded values.\n",
        "    train_loss = sum(train_loss) / len(train_loss)\n",
        "    train_acc = sum(train_accs) / len(train_accs)\n",
        "\n",
        "    # Print the information.\n",
        "    print(f\"[ Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}\")\n",
        "\n",
        "    # ---------- Validation ----------\n",
        "    model_resnet50.eval()\n",
        "\n",
        "    # These are used to record information in validation.\n",
        "    valid_loss = []\n",
        "    valid_accs = []\n",
        "\n",
        "    # Iterate the validation set by batches.\n",
        "    for batch in tqdm(valid_loader):\n",
        "        \n",
        "        imgs, labels = batch\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = model_resnet50(imgs.to(device))\n",
        "\n",
        "        loss = criterion(logits, labels.to(device))\n",
        "\n",
        "        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n",
        "\n",
        "        # Record the loss and accuracy.\n",
        "        valid_loss.append(loss.item())\n",
        "        valid_accs.append(acc)\n",
        "\n",
        "    # The average loss and accuracy for entire validation set is the average of the recorded values.\n",
        "    valid_loss = sum(valid_loss) / len(valid_loss)\n",
        "    valid_acc = sum(valid_accs) / len(valid_accs)\n",
        "\n",
        "    # Print the information.\n",
        "    print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n",
        "    \n",
        "    # ------Record every time information------\n",
        "    if valid_acc > best_acc:\n",
        "        best_acc = valid_acc\n",
        "        torch.save(model_resnet50.state_dict(), ResNet50_save_path)\n",
        "    train_loss_record.append(train_loss)\n",
        "    valid_loss_record.append(valid_loss)\n",
        "    train_acc_record.append(train_acc)\n",
        "    valid_acc_record.append(valid_acc)"
      ],
      "metadata": {
        "id": "KBq1RL5cVc4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_resnet50.load_state_dict(torch.load(ResNet50_save_path))\n",
        "\n",
        "model_resnet50.eval()\n",
        "\n",
        "test_loss = []\n",
        "test_accs = []\n",
        "test_acc = []\n",
        "\n",
        "for batch in tqdm(test_loader):\n",
        "    imgs, labels = batch\n",
        "  \n",
        "    with torch.no_grad():\n",
        "        logits = model_resnet50(imgs.to(device))\n",
        "  \n",
        "    loss = criterion(logits, labels.to(device))\n",
        "    acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n",
        "\n",
        "    test_loss.append(loss)\n",
        "    test_accs.append(acc)\n",
        "\n",
        "test_loss = sum(test_loss)/len(test_loss)\n",
        "test_acc = sum(test_accs)/len(test_accs)\n",
        "print(f\"loss = {test_loss:.5f}, acc = {test_acc:.5f}\")"
      ],
      "metadata": {
        "id": "OIWT3WFXVgsw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}